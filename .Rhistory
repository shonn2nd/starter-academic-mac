ggplot(aes(n, word)) +
geom_col() +
labs(y = NULL) +
labs(x = "Frequency")
View(toks)
toks<-bio_clean %>% unnest_tokens(word, text, token = "ngrams", n = 3)
toks%>%
count(word, sort = TRUE) %>%
filter(n > 60) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(n, word)) +
geom_col() +
labs(y = NULL) +
labs(x = "Frequency")
toks%>%
count(word, sort = TRUE) %>%
filter(n > 20) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(n, word)) +
geom_col() +
labs(y = NULL) +
labs(x = "Frequency")
toks%>%
count(word, sort = TRUE) %>%
filter(n > 1) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(n, word)) +
geom_col() +
labs(y = NULL) +
labs(x = "Frequency")
toks%>%
count(word, sort = TRUE) %>%
filter(n > 2) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(n, word)) +
geom_col() +
labs(y = NULL) +
labs(x = "Frequency")
toks%>%
count(word, sort = TRUE) %>%
filter(n > 4) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(n, word)) +
geom_col() +
labs(y = NULL) +
labs(x = "Frequency")
toks%>%
count(word, sort = TRUE) %>%
filter(n > 5) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(n, word)) +
geom_col() +
labs(y = NULL) +
labs(x = "Frequency")
toks<-bio_clean %>% unnest_tokens(word, text, token = "ngrams", n = 2)
toks%>%
count(word, sort = TRUE) %>%
filter(n > 5) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(n, word)) +
geom_col() +
labs(y = NULL) +
labs(x = "Frequency")
toks%>%
count(word, sort = TRUE) %>%
filter(n > 10) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(n, word)) +
geom_col() +
labs(y = NULL) +
labs(x = "Frequency")
toks%>%
count(word, sort = TRUE) %>%
filter(n > 20) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(n, word)) +
geom_col() +
labs(y = NULL) +
labs(x = "Frequency")
toks%>%
count(word, sort = TRUE) %>%
filter(n > 8) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(n, word)) +
geom_col() +
labs(y = NULL) +
labs(x = "Frequency")
library(blogdown)
blogdown:::serve_site()
rm(list=ls())
knitr::opts_chunk$set(echo = TRUE)
```{r, message=F}
```{r message=FALSE}
#loading necessary packages
library(rvest)
library(xml2)
library(tidyverse)
library(tidytext)
img1_path <- "images/tn.png"
img1 <- readPNG(img1_path, native = TRUE, info = TRUE)
library(png)
img1 <- readPNG(img1_path, native = TRUE, info = TRUE)
img1_path
library(png)
img1 <- readPNG(img1_path, native = TRUE, info = TRUE)
img1_path <- "/Users/shsu/OneDrive/website/starter-academic-mac/content/post/chinese character in ggplot/wang.png"
img1 <- readPNG(img1_path, native = TRUE, info = TRUE)
img1
include_graphics(img1_path)
library(knitr)
include_graphics(img1_path)
blogdown:::serve_site()
img1
img1_path <- "/Users/shsu/OneDrive/website/starter-academic-mac/content/post/chinese character in ggplot/wang.png"
include_graphics(img1_path)
library(blogdown)
blogdown:::serve_site()
knitr::opts_chunk$set(echo = TRUE)
img1_path <- "/Users/shsu/OneDrive/website/starter-academic-mac/content/post/chinese character in ggplot/wang.png"
include_graphics(img1_path)
#loading necessary packages
library(rvest)
library(xml2)
library(tidyverse)
library(tidytext)
library(png)
library(knitr)
img1_path <- "/Users/shsu/OneDrive/website/starter-academic-mac/content/post/chinese character in ggplot/wang.png"
include_graphics(img1_path)
knitr::include_graphics('wang.png')
knitr::include_graphics(/'wang.png')
knitr::include_graphics('/wang.png')
knitr::include_graphics('static/wang.png')
knitr::include_graphics('/static/wang.png')
knitr::include_graphics('wang.png')
knitr::include_graphics('/images/wang.png')
knitr::include_graphics('/Users/shsu/OneDrive/website/starter-academic-mac/images/images/wang.png')
knitr::include_graphics('/Users/shsu/OneDrive/website/starter-academic-mac/images/wang.png')
knitr::include_graphics('/Users/shsu/OneDrive/website/starter-academic-mac/images/wang.png')
knitr::include_graphics('wang.png')
knitr::include_graphics(wang.png)
knitr::include_graphics(../../static/wang.png)
knitr::include_graphics(../../static/wang.png)
knitr::include_graphics(../../static/wang.png)
knitr::include_graphics(../../static/wang.png)
knitr::include_graphics(../../static/wang.png)
knitr::include_graphics(../../static/wang.png)
knitr::include_graphics(../../static/wang.png)
![xx](wang.png)
![xx]("wang.png")
knitr::include_graphics(../../static/wang.png)
knitr::include_graphics(static/wang.png)
knitr::include_graphics(static/wang.png)
knitr::include_graphics(static/wang.png)
knitr::include_graphics(static/wang.png)
knitr::include_graphics("static/wang.png")
knitr::include_graphics("/static/wang.png")
knitr::include_graphics("/static/wang.png")
knitr::include_graphics("/static/wang.png")
knitr::include_graphics(wang.png)
knitr::include_graphics(/images/wang.png)
knitr::include_graphics(/images/wang.png)
knitr::include_graphics(/images/wang.png)
knitr::include_graphics(images/wang.png)
knitr::include_graphics("images/wang.png")
knitr::include_graphics("/images/wang.png")
knitr::include_graphics("static/images/wang.png")
knitr::include_graphics("/Users/shsu/OneDrive/website/starter-academic-mac/static/images/wang.png")
library(blogdown)
blogdown:::serve_site()
knitr::opts_chunk$set(echo = TRUE)
knitr::include_graphics("/Users/shsu/OneDrive/website/starter-academic-mac/static/images/wang.png")
knitr::include_graphics("/Users/shsu/OneDrive/website/starter-academic-mac/static/images/wang.png")
wang <- "https://zh.wikipedia.org/wiki/%E7%8E%8B%E5%BB%BA%E6%B0%91_(%E6%A3%92%E7%90%83%E5%93%A1)"
wanghtml <- read_html(wang)
#loading necessary packages
library(rvest)
library(xml2)
library(tidyverse)
library(tidytext)
library(png)
library(knitr)
wang <- "https://zh.wikipedia.org/wiki/%E7%8E%8B%E5%BB%BA%E6%B0%91_(%E6%A3%92%E7%90%83%E5%93%A1)"
wanghtml <- read_html(wang)
wanghtml
str(wanghtml)
knitr::include_graphics('/static/images/wang.png')
![Willie](/static/imgages/featured.png)
knitr::include_graphics('static/images/featured.png')
knitr::include_graphics('/static/images/featured.png')
knitr::include_graphics('/static/images/featured.png')
knitr::include_graphics('/static/images/featured.png')
knitr::include_graphics('/static/images/featured.png')
knitr::include_graphics(/static/images/featured.png)
knitr::include_graphics(static/images/featured.png)
knitr::include_graphics("/Users/shsu/OneDrive/website/starter-academic-mac/content/post/chinese character in ggplot/index_files/figure-html/wang.png")
knitr::opts_chunk$set(echo = TRUE)
#loading necessary packages
library(rvest)
library(xml2)
library(tidyverse)
library(tidytext)
library(png)
library(knitr)
knitr::opts_chunk$set(echo = TRUE)
#loading necessary packages
library(rvest)
library(xml2)
library(tidyverse)
library(tidytext)
library(png)
library(knitr)
knitr::include_graphics("/Users/shsu/OneDrive/website/starter-academic-mac/static/images/wang.png")
library(blogdown)
blogdown:::serve_site()
knitr::opts_chunk$set(echo = TRUE)
#loading necessary packages
library(rvest)
library(xml2)
library(tidyverse)
library(tidytext)
library(png)
library(knitr)
?read_html
#get access to Wang's wiki
wang <- "https://zh.wikipedia.org/wiki/%E7%8E%8B%E5%BB%BA%E6%B0%91_(%E6%A3%92%E7%90%83%E5%93%A1)"
#read html
wanghtml <- read_html(wang)
#check html
wanghtml
#compactly display the structure of the webpage
str(wanghtml)
body_nodes <- wanghtml %>%
html_node("body") %>%
html_children()
body_nodes
bio <- wanghtml %>%
rvest::html_nodes('body') %>%
xml2::xml_find_all("//div[contains(@class, 'mw-body-content mw-content-ltr')]") %>%
rvest::html_text()
bio_df <- data.frame(bio)
bio_df<-gsub("臺灣出生大聯盟選手列表.*","",bio_df)
bio_df <- data.frame(bio_df)
bio_df<-bio_df %>% rename(text = 1)
#let's take a look at our text data
glimpse(bio_df)
bio <- wanghtml %>%
rvest::html_nodes('body') %>%
xml2::xml_find_all("//div[contains(@class, 'mw-body-content mw-content-ltr')]") %>%
rvest::html_text()
bio_df <- data.frame(bio)
bio_df<-gsub("臺灣出生大聯盟選手列表.*","",bio_df)
bio_df <- data.frame(bio_df)
bio_df<-bio_df %>% rename(text = 1)
#let's take a look at our text data
bio_df
#our raw text data
bio_df <- data.frame(bio)
View(bio_df)
#remove the part in this wiki that is not related to his bio
bio_df<-gsub("臺灣出生大聯盟選手列表.*","",bio_df)
bio <- wanghtml %>%
rvest::html_nodes('body') %>%
xml2::xml_find_all("//div[contains(@class, 'mw-body-content mw-content-ltr')]") %>%
rvest::html_text()
#our raw text data
bio_df <- data.frame(bio)
bio_df<-bio_df %>% rename(text = 1)
#remove the part in this wiki that is not related to his bio
bio_df<-gsub("臺灣出生大聯盟選手列表.*","",bio_df)
#remove numbers, punctuation, and English words
bio_clean<-bio_df$text %>%
str_remove_all("\\n|[:digit:]|[:lower:]|[:upper:]|[:punct:]") %>% as.data.frame()
bio <- wanghtml %>%
rvest::html_nodes('body') %>%
xml2::xml_find_all("//div[contains(@class, 'mw-body-content mw-content-ltr')]") %>%
rvest::html_text()
#our raw text data
bio_df <- data.frame(bio)
bio_df<-bio_df %>% rename(text = 1)
#remove the part in this wiki that is not related to his bio
bio_df<-gsub("臺灣出生大聯盟選手列表.*","",bio_df)
#remove numbers, punctuation, and English words
bio_clean<-bio_df%>%
str_remove_all(text, "\\n|[:digit:]|[:lower:]|[:upper:]|[:punct:]") %>% as.data.frame()
bio <- wanghtml %>%
rvest::html_nodes('body') %>%
xml2::xml_find_all("//div[contains(@class, 'mw-body-content mw-content-ltr')]") %>%
rvest::html_text()
#our raw text data
bio_df <- data.frame(bio)
bio_df<-bio_df %>% rename(text = 1)
#remove the part in this wiki that is not related to his bio
bio_df<-gsub("臺灣出生大聯盟選手列表.*","",bio_df)
bio_df<-as.data.frame(bio_df)
#remove numbers, punctuation, and English words
bio_clean<-bio_df$text%>%
str_remove_all("\\n|[:digit:]|[:lower:]|[:upper:]|[:punct:]") %>% as.data.frame()
#let's take a look at our cleaned text data
bio_clean
View(bio_clean)
#our raw text data
bio_df <- data.frame(bio)
View(bio_df)
bio_df<-bio_df %>% rename(text = 1)
#remove the part in this wiki that is not related to his bio
bio_df<-gsub("臺灣出生大聯盟選手列表.*","",bio_df)
#remove the part in this wiki that is not related to his bio
bio_df<-as.data.frame(gsub("臺灣出生大聯盟選手列表.*","",bio_df))
View(bio_df)
#remove numbers, punctuation, and English words
bio_df$text %>%
str_remove_all("\\n|[:digit:]|[:lower:]|[:upper:]|[:punct:]")
View(bio_df)
#remove the part in this wiki that is not related to his bio
bio_df<-gsub("臺灣出生大聯盟選手列表.*","",bio_df)
#our raw text data
bio_df <- data.frame(bio)
bio_df<-bio_df %>% rename(text = 1)
#remove the part in this wiki that is not related to his bio
bio_df<-gsub("臺灣出生大聯盟選手列表.*","",bio_df)
bio_df
bio_df<-as.data.frame(bio_df)
bio_df
#remove numbers, punctuation, and English words
bio_df$text %>%
str_remove_all("\\n|[:digit:]|[:lower:]|[:upper:]|[:punct:]")
View(bio_df)
bio_d
bio_df
bio_df<-bio_df %>% rename(text = 1)
#remove numbers, punctuation, and English words
bio_df$text %>%
str_remove_all("\\n|[:digit:]|[:lower:]|[:upper:]|[:punct:]")
#find all the <div> nodes in the body of the page that have a class name containing 'mw-body-content mw-content-ltr'
bio <- wanghtml %>%
rvest::html_nodes('body') %>%
xml2::xml_find_all("//div[contains(@class, 'mw-body-content mw-content-ltr')]") %>%
rvest::html_text()
#finally, we have our raw text data
bio_df <- data.frame(bio)
#clean the raw data a little bit
#remove the part in the wiki that is not related to his bio
bio_df<-gsub("臺灣出生大聯盟選手列表.*","",bio_df)
bio_df<-as.data.frame(bio_df)
bio_df<-bio_df %>% rename(text = 1)
#remove numbers, punctuation, and English words
bio_clean<-bio_df$text %>%
str_remove_all("\\n|[:digit:]|[:lower:]|[:upper:]|[:punct:]")
#now we have our clean data that is ready for analysis and visualization
bio_cean
#find all the <div> nodes in the body of the page that have a class name containing 'mw-body-content mw-content-ltr'
bio <- wanghtml %>%
rvest::html_nodes('body') %>%
xml2::xml_find_all("//div[contains(@class, 'mw-body-content mw-content-ltr')]") %>%
rvest::html_text()
#finally, we have our raw text data
bio_df <- data.frame(bio)
#clean the raw data a little bit
#remove the part in the wiki that is not related to his bio
bio_df<-gsub("臺灣出生大聯盟選手列表.*","",bio_df)
bio_df<-as.data.frame(bio_df)
bio_df<-bio_df %>% rename(text = 1)
#remove numbers, punctuation, and English words
bio_clean<-bio_df$text %>%
str_remove_all("\\n|[:digit:]|[:lower:]|[:upper:]|[:punct:]")
#now we have our clean data that is ready for analysis and visualization
bio_clean
bio_clean
#find all the <div> nodes in the body of the page that have a class name containing 'mw-body-content mw-content-ltr'
bio <- wanghtml %>%
rvest::html_nodes('body') %>%
xml2::xml_find_all("//div[contains(@class, 'mw-body-content mw-content-ltr')]") %>%
rvest::html_text()
#finally, we have our raw text data
bio_df <- data.frame(bio)
#clean the raw data a little bit
#remove the part in the wiki that is not related to his bio
bio_df<-gsub("臺灣出生大聯盟選手列表.*","",bio_df)
bio_df<-as.data.frame(bio_df)
bio_df<-bio_df %>% rename(text = 1)
#remove numbers, punctuation, and English words
bio_clean<-bio_df$text %>%
str_remove_all("\\n|[:digit:]|[:lower:]|[:upper:]|[:punct:]")
#now we have our clean data that is ready for analysis and visualization
bio_clean<-as.data.frame(bio_clean)
bio_clean<-bio_clean %>% rename(text = 1)
bio_clean
View(bio_clean)
#find all the <div> nodes in the body of the page that have a class name containing 'mw-body-content mw-content-ltr'
bio <- wanghtml %>%
rvest::html_nodes('body') %>%
xml2::xml_find_all("//div[contains(@class, 'mw-body-content mw-content-ltr')]") %>%
rvest::html_text()
#finally, we have our raw text data
bio_df <- data.frame(bio)
#clean the raw data a little bit
#remove the part in the wiki that is not related to his bio
bio_df<-gsub("臺灣出生大聯盟選手列表.*","",bio_df)
bio_df<-as.data.frame(bio_df)
bio_df<-bio_df %>% rename(text = 1)
#remove numbers, punctuation, and English words
bio_clean<-bio_df$text %>%
str_remove_all("\\n|[:digit:]|[:lower:]|[:upper:]|[:punct:]")
#now we have our clean data that is ready for analysis and visualization
bio_clean
#tokenization of your text data
bio_clean<-as.data.frame(bio_clean)
bio_clean<-bio_clean %>% rename(text = 1)
toks<-bio_clean %>%
unnest_tokens(word, text)
toks%>%
count(word, sort = TRUE) %>%
filter(n > 60) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(n, word)) +
geom_col() +
labs(y = NULL)
library(blogdown)
blogdown:::serve_site()
library(blogdown)
blogdown:::serve_site()
library(blogdown)
blogdown:::serve_site()
blogdown::install_hugo()
blogdown::serve_site()
library(blogdown)
blogdown::serve_site()
blogdown::build_site()
source("~/Desktop/starter-academic-mac/content/post/test/index.Rmarkdown")
blogdown::serve_site()
library(blogdown)
blogdown::install_hugo(force = TRUE)
library(blogdown)
blogdown::serve_site()
blogdown::build_site()
blogdown::serve_site()
blogdown::build_site()
install.packages("languageserver")
library(languageserver)
install.packages("rmarkdown")
install.packages("rmarkdown")
knit_with_parameters("~/Desktop/starter-academic-mac/content/post/test/test.Rmd")
install.packages(rmarkdown)
install.packages("rmarkdown")
install.packages("rmarkdown")
installed.packages("rmarkdown")
detach("package:rmarkdown", unload = TRUE)
install.packages("rmarkdown")
.libPaths(rmarkdown)
.libPaths("rmarkdown")
.libPaths()
installed.packages("rmarkdown")
install.packages("rmarkdown")
library(rmarkdown)
detach("package:rmarkdown", unload = TRUE)
library(rmarkdown)
knit_with_parameters("~/Desktop/starter-academic-mac/content/post/test/test.Rmd")
install.packages("fastDummies")
library(fastDummies)
library(fastDummies)
# Create a vector of race scores
race <- c("White", "Black", "Asian", "Hispanic", "Other")
# Generate random income values for each race
set.seed(123) # for reproducibility
income <- round(runif(length(race), min = 20000, max = 100000), digits = 2)
# Combine race and income into a data frame
data <- data.frame(race, income)
# Print the dataset
print(data)
View(data)
# Create a vector of race scores
race <- c("White", "Black", "Asian", "Hispanic", "Other")
# Generate random income values for each race (100 cases)
set.seed(123) # for reproducibility
income <- round(runif(100, min = 20000, max = 100000), digits = 2)
# Repeat each race 20 times to get 100 cases
race <- rep(race, each = 20)
# Combine race and income into a data frame
data <- data.frame(race, income)
# Print the first few rows of the dataset
print(head(data))
View(data)
data %>% dummy_cols(race)
data %>% dummy_cols(race)
library(fastDummies)
library(tidyverse)
# Create a vector of race scores
race <- c("White", "Black", "Asian", "Hispanic", "Other")
# Generate random income values for each race (100 cases)
set.seed(123) # for reproducibility
income <- round(runif(100, min = 20000, max = 100000), digits = 2)
# Repeat each race 20 times to get 100 cases
race <- rep(race, each = 20)
# Combine race and income into a data frame
data <- data.frame(race, income)
# Print the first few rows of the dataset
print(head(data))
data |>  dummy_cols(race)
names(data)
data %>% dummy_cols(race)
library(fastDummies)
library(tidyverse)
data %>% dummy_columns(race)
data |>  dummy_columns(race)
data |> dummy_cols(select_columns = "race")
data<-data |> dummy_cols(select_columns = "race")
View(data)
install.packages("psych")
names(data)
fit<-lm(income ~ race_Asian + race_Hispanic + race_Other + race_White, data=data)
summary(fit)
