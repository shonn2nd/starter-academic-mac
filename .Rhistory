bio_df <- data.frame(bio)
bio_df<-gsub("臺灣出生大聯盟選手列表.*","",bio_df)
bio_df <- data.frame(bio_df)
bio_df<-bio_df %>% rename(text = 1)
#let's take a look at our text data
glimpse(bio_df)
bio <- wanghtml %>%
rvest::html_nodes('body') %>%
xml2::xml_find_all("//div[contains(@class, 'mw-body-content mw-content-ltr')]") %>%
rvest::html_text()
bio_df <- data.frame(bio)
bio_df<-gsub("臺灣出生大聯盟選手列表.*","",bio_df)
bio_df <- data.frame(bio_df)
bio_df<-bio_df %>% rename(text = 1)
#let's take a look at our text data
bio_df
#our raw text data
bio_df <- data.frame(bio)
View(bio_df)
#remove the part in this wiki that is not related to his bio
bio_df<-gsub("臺灣出生大聯盟選手列表.*","",bio_df)
bio <- wanghtml %>%
rvest::html_nodes('body') %>%
xml2::xml_find_all("//div[contains(@class, 'mw-body-content mw-content-ltr')]") %>%
rvest::html_text()
#our raw text data
bio_df <- data.frame(bio)
bio_df<-bio_df %>% rename(text = 1)
#remove the part in this wiki that is not related to his bio
bio_df<-gsub("臺灣出生大聯盟選手列表.*","",bio_df)
#remove numbers, punctuation, and English words
bio_clean<-bio_df$text %>%
str_remove_all("\\n|[:digit:]|[:lower:]|[:upper:]|[:punct:]") %>% as.data.frame()
bio <- wanghtml %>%
rvest::html_nodes('body') %>%
xml2::xml_find_all("//div[contains(@class, 'mw-body-content mw-content-ltr')]") %>%
rvest::html_text()
#our raw text data
bio_df <- data.frame(bio)
bio_df<-bio_df %>% rename(text = 1)
#remove the part in this wiki that is not related to his bio
bio_df<-gsub("臺灣出生大聯盟選手列表.*","",bio_df)
#remove numbers, punctuation, and English words
bio_clean<-bio_df%>%
str_remove_all(text, "\\n|[:digit:]|[:lower:]|[:upper:]|[:punct:]") %>% as.data.frame()
bio <- wanghtml %>%
rvest::html_nodes('body') %>%
xml2::xml_find_all("//div[contains(@class, 'mw-body-content mw-content-ltr')]") %>%
rvest::html_text()
#our raw text data
bio_df <- data.frame(bio)
bio_df<-bio_df %>% rename(text = 1)
#remove the part in this wiki that is not related to his bio
bio_df<-gsub("臺灣出生大聯盟選手列表.*","",bio_df)
bio_df<-as.data.frame(bio_df)
#remove numbers, punctuation, and English words
bio_clean<-bio_df$text%>%
str_remove_all("\\n|[:digit:]|[:lower:]|[:upper:]|[:punct:]") %>% as.data.frame()
#let's take a look at our cleaned text data
bio_clean
View(bio_clean)
#our raw text data
bio_df <- data.frame(bio)
View(bio_df)
bio_df<-bio_df %>% rename(text = 1)
#remove the part in this wiki that is not related to his bio
bio_df<-gsub("臺灣出生大聯盟選手列表.*","",bio_df)
#remove the part in this wiki that is not related to his bio
bio_df<-as.data.frame(gsub("臺灣出生大聯盟選手列表.*","",bio_df))
View(bio_df)
#remove numbers, punctuation, and English words
bio_df$text %>%
str_remove_all("\\n|[:digit:]|[:lower:]|[:upper:]|[:punct:]")
View(bio_df)
#remove the part in this wiki that is not related to his bio
bio_df<-gsub("臺灣出生大聯盟選手列表.*","",bio_df)
#our raw text data
bio_df <- data.frame(bio)
bio_df<-bio_df %>% rename(text = 1)
#remove the part in this wiki that is not related to his bio
bio_df<-gsub("臺灣出生大聯盟選手列表.*","",bio_df)
bio_df
bio_df<-as.data.frame(bio_df)
bio_df
#remove numbers, punctuation, and English words
bio_df$text %>%
str_remove_all("\\n|[:digit:]|[:lower:]|[:upper:]|[:punct:]")
View(bio_df)
bio_d
bio_df
bio_df<-bio_df %>% rename(text = 1)
#remove numbers, punctuation, and English words
bio_df$text %>%
str_remove_all("\\n|[:digit:]|[:lower:]|[:upper:]|[:punct:]")
#find all the <div> nodes in the body of the page that have a class name containing 'mw-body-content mw-content-ltr'
bio <- wanghtml %>%
rvest::html_nodes('body') %>%
xml2::xml_find_all("//div[contains(@class, 'mw-body-content mw-content-ltr')]") %>%
rvest::html_text()
#finally, we have our raw text data
bio_df <- data.frame(bio)
#clean the raw data a little bit
#remove the part in the wiki that is not related to his bio
bio_df<-gsub("臺灣出生大聯盟選手列表.*","",bio_df)
bio_df<-as.data.frame(bio_df)
bio_df<-bio_df %>% rename(text = 1)
#remove numbers, punctuation, and English words
bio_clean<-bio_df$text %>%
str_remove_all("\\n|[:digit:]|[:lower:]|[:upper:]|[:punct:]")
#now we have our clean data that is ready for analysis and visualization
bio_cean
#find all the <div> nodes in the body of the page that have a class name containing 'mw-body-content mw-content-ltr'
bio <- wanghtml %>%
rvest::html_nodes('body') %>%
xml2::xml_find_all("//div[contains(@class, 'mw-body-content mw-content-ltr')]") %>%
rvest::html_text()
#finally, we have our raw text data
bio_df <- data.frame(bio)
#clean the raw data a little bit
#remove the part in the wiki that is not related to his bio
bio_df<-gsub("臺灣出生大聯盟選手列表.*","",bio_df)
bio_df<-as.data.frame(bio_df)
bio_df<-bio_df %>% rename(text = 1)
#remove numbers, punctuation, and English words
bio_clean<-bio_df$text %>%
str_remove_all("\\n|[:digit:]|[:lower:]|[:upper:]|[:punct:]")
#now we have our clean data that is ready for analysis and visualization
bio_clean
bio_clean
#find all the <div> nodes in the body of the page that have a class name containing 'mw-body-content mw-content-ltr'
bio <- wanghtml %>%
rvest::html_nodes('body') %>%
xml2::xml_find_all("//div[contains(@class, 'mw-body-content mw-content-ltr')]") %>%
rvest::html_text()
#finally, we have our raw text data
bio_df <- data.frame(bio)
#clean the raw data a little bit
#remove the part in the wiki that is not related to his bio
bio_df<-gsub("臺灣出生大聯盟選手列表.*","",bio_df)
bio_df<-as.data.frame(bio_df)
bio_df<-bio_df %>% rename(text = 1)
#remove numbers, punctuation, and English words
bio_clean<-bio_df$text %>%
str_remove_all("\\n|[:digit:]|[:lower:]|[:upper:]|[:punct:]")
#now we have our clean data that is ready for analysis and visualization
bio_clean<-as.data.frame(bio_clean)
bio_clean<-bio_clean %>% rename(text = 1)
bio_clean
View(bio_clean)
#find all the <div> nodes in the body of the page that have a class name containing 'mw-body-content mw-content-ltr'
bio <- wanghtml %>%
rvest::html_nodes('body') %>%
xml2::xml_find_all("//div[contains(@class, 'mw-body-content mw-content-ltr')]") %>%
rvest::html_text()
#finally, we have our raw text data
bio_df <- data.frame(bio)
#clean the raw data a little bit
#remove the part in the wiki that is not related to his bio
bio_df<-gsub("臺灣出生大聯盟選手列表.*","",bio_df)
bio_df<-as.data.frame(bio_df)
bio_df<-bio_df %>% rename(text = 1)
#remove numbers, punctuation, and English words
bio_clean<-bio_df$text %>%
str_remove_all("\\n|[:digit:]|[:lower:]|[:upper:]|[:punct:]")
#now we have our clean data that is ready for analysis and visualization
bio_clean
#tokenization of your text data
bio_clean<-as.data.frame(bio_clean)
bio_clean<-bio_clean %>% rename(text = 1)
toks<-bio_clean %>%
unnest_tokens(word, text)
toks%>%
count(word, sort = TRUE) %>%
filter(n > 60) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(n, word)) +
geom_col() +
labs(y = NULL)
library(blogdown)
blogdown:::serve_site()
library(blogdown)
blogdown:::serve_site()
library(blogdown)
blogdown:::serve_site()
blogdown::install_hugo()
blogdown::serve_site()
library(blogdown)
blogdown::serve_site()
blogdown::build_site()
source("~/Desktop/starter-academic-mac/content/post/test/index.Rmarkdown")
blogdown::serve_site()
library(blogdown)
blogdown::install_hugo(force = TRUE)
library(blogdown)
blogdown::serve_site()
blogdown::build_site()
blogdown::serve_site()
blogdown::build_site()
install.packages("languageserver")
library(languageserver)
install.packages("rmarkdown")
install.packages("rmarkdown")
knit_with_parameters("~/Desktop/starter-academic-mac/content/post/test/test.Rmd")
install.packages(rmarkdown)
install.packages("rmarkdown")
install.packages("rmarkdown")
installed.packages("rmarkdown")
detach("package:rmarkdown", unload = TRUE)
install.packages("rmarkdown")
.libPaths(rmarkdown)
.libPaths("rmarkdown")
.libPaths()
installed.packages("rmarkdown")
install.packages("rmarkdown")
library(rmarkdown)
detach("package:rmarkdown", unload = TRUE)
library(rmarkdown)
knit_with_parameters("~/Desktop/starter-academic-mac/content/post/test/test.Rmd")
install.packages("fastDummies")
library(fastDummies)
library(fastDummies)
# Create a vector of race scores
race <- c("White", "Black", "Asian", "Hispanic", "Other")
# Generate random income values for each race
set.seed(123) # for reproducibility
income <- round(runif(length(race), min = 20000, max = 100000), digits = 2)
# Combine race and income into a data frame
data <- data.frame(race, income)
# Print the dataset
print(data)
View(data)
# Create a vector of race scores
race <- c("White", "Black", "Asian", "Hispanic", "Other")
# Generate random income values for each race (100 cases)
set.seed(123) # for reproducibility
income <- round(runif(100, min = 20000, max = 100000), digits = 2)
# Repeat each race 20 times to get 100 cases
race <- rep(race, each = 20)
# Combine race and income into a data frame
data <- data.frame(race, income)
# Print the first few rows of the dataset
print(head(data))
View(data)
data %>% dummy_cols(race)
data %>% dummy_cols(race)
library(fastDummies)
library(tidyverse)
# Create a vector of race scores
race <- c("White", "Black", "Asian", "Hispanic", "Other")
# Generate random income values for each race (100 cases)
set.seed(123) # for reproducibility
income <- round(runif(100, min = 20000, max = 100000), digits = 2)
# Repeat each race 20 times to get 100 cases
race <- rep(race, each = 20)
# Combine race and income into a data frame
data <- data.frame(race, income)
# Print the first few rows of the dataset
print(head(data))
data |>  dummy_cols(race)
names(data)
data %>% dummy_cols(race)
library(fastDummies)
library(tidyverse)
data %>% dummy_columns(race)
data |>  dummy_columns(race)
data |> dummy_cols(select_columns = "race")
data<-data |> dummy_cols(select_columns = "race")
View(data)
install.packages("psych")
names(data)
fit<-lm(income ~ race_Asian + race_Hispanic + race_Other + race_White, data=data)
summary(fit)
library(haven)
library(tidyverse)
library(labelled)
library(devtools)
install_github("https://github.com/cran/userfriendlyscience")
library(userfriendlyscience)
data$RECOGBEGIN
data<-read_sav("nsch.sav")
data<-read_sav("static/uploads/nsch.sav")
data_c<-remove_labels(data)
data$RECOGBEGIN
table(data$RECOGBEGIN)
table(data$RECOGBEGIN)
table(data$CLEAREXP)
table(data$RECOGBEGIN)
table(data$CLEAREXP)
table(data$WRITENAME)
table(data$RECOGBEGIN)
table(data$CLEAREXP)
table(data$WRITENAME)
table(data$RECSHAPES)
table(data$RECOGBEGIN)
table(data$CLEAREXP)
table(data$WRITENAME)
table(data$RECSHAPES)
data %>% filter(RECOGBEGIN < 6 & CLEAREXP < 6 & WRITENAME < 6 & RECSHAPES < 6)
?across
table(data$RECOGBEGIN)
table(data$CLEAREXP)
table(data$WRITENAME)
table(data$RECSHAPES)
data %>% filter(across(c(RECOGBEGIN, CLEAREXP, WRITENAME, RECSHAPES), ~ . < 6))
?filter
data<-data %>% filter(across(c(RECOGBEGIN, CLEAREXP, WRITENAME, RECSHAPES), ~ . < 6))
plot.new()
data %>%
filter(across(c(RECOGBEGIN, CLEAREXP, WRITENAME, RECSHAPES), ~ . < 6)) %>%
select(RECOGBEGIN, CLEAREXP, WRITENAME, RECSHAPES) %>%
scaleStructure()
install.packages("psychTools")
library(psychTools)
library(haven)
library(tidyverse)
library(labelled)
library(userfriendlyscience)
library(psychTools)
plot.new()
data %>%
filter(across(c(RECOGBEGIN, CLEAREXP, WRITENAME, RECSHAPES), ~ . < 6)) %>%
select(RECOGBEGIN, CLEAREXP, WRITENAME, RECSHAPES) %>%
scaleStructure()
detach("package:psychTools", unload = TRUE)
install.packages("blogdown")
library(blogdown)
blogdown::serve_site()
install.packages("chatgpt")
library(chatgpt)
?chatgpt
?`chatgpt-package`
cat(ask_chatgpt("What do you think about R language?"))
library(haven)
df <- read_sav("~/Downloads/ICPSR3510.sav")
View(df)
names(df)
df
glimpse(mpg)
library(tidyverse)
glimpse(mpg)
mpg %>%
ggplot(mapping = aes(trans)) +
geom_bar()
mpg %>%
group_by(trans) %>%
count() %>%
ungroup() %>%
ggplot(mapping = aes(trans, n)) +
geom_bar(stat = "identity")
mpg %>%
group_by(trans) %>%
count() %>%
ungroup() %>%
ggplot(mapping = aes(reorder(trans, n), n)) +
geom_bar(stat = "identity")
mpg %>%
group_by(trans) %>%
count() %>%
ungroup() %>%
ggplot(mapping = aes(trans, n)) +
geom_bar(stat = "identity")
mpg %>%
group_by(trans) %>%
count() %>%
ungroup() %>%
ggplot(mapping = aes(reorder(trans, n), n)) +
geom_bar(stat = "identity")
glimpse(mpg)
mpg %>%
group_by(class, trans) %>%
count() %>%
ungroup() %>%
ggplot(mapping = aes(reorder(trans, n), n)) +
geom_bar(stat = "identity") +
facet_wrap(~ class)
#load packages
library(tidyverse)
library(tidytext)
mpg %>%
group_by(class, trans) %>%
count() %>%
ungroup() %>%
ggplot(mapping = aes(reorder(trans, n), n)) +
geom_bar(stat = "identity") +
facet_wrap(~ class)
mpg %>%
ggplot(mapping = aes(reorder_within(trans, n, class), n)) +
geom_bar(stat = "identity") +
facet_wrap(~ class)
mpg %>%
group_by(class, trans) %>%
count() %>%
ungroup() %>%
ggplot(mapping = aes(reorder(trans, n), n)) +
geom_bar(stat = "identity") +
facet_wrap(~ class)
mpg %>%
group_by(class, trans) %>%
count() %>%
ungroup() %>%
ggplot(mapping = aes(reorder_within(trans, n, class), n)) +
geom_bar(stat = "identity") +
facet_wrap(~ class)
mpg %>%
group_by(class, trans) %>%
count() %>%
ungroup() %>%
ggplot(mapping = aes(reorder_within(trans, n, class), n)) +
geom_bar(stat = "identity", binwidth = 0.5) +
facet_wrap(~ class)
mpg %>%
group_by(class, trans) %>%
count() %>%
ungroup() %>%
ggplot(mapping = aes(reorder_within(trans, n, class), n)) +
geom_bar(stat = "identity", binwidth = 1) +
facet_wrap(~ class)
mpg %>%
group_by(class, trans) %>%
count() %>%
ungroup() %>%
ggplot(mapping = aes(reorder(trans, n), n)) +
geom_bar(stat = "identity") +
facet_wrap(~ class)
mpg %>%
group_by(class, trans) %>%
count() %>%
ungroup() %>%
ggplot(mapping = aes(reorder_within(trans, n, class), n)) +
geom_bar(stat = "identity") +
facet_wrap(~ class)
mpg %>%
group_by(class, trans) %>%
count() %>%
ungroup() %>%
ggplot(mapping = aes(reorder_within(trans, n, class), n)) +
geom_bar(stat = "identity", scale = "free_x") +
facet_wrap(~ class)
mpg %>%
group_by(class, trans) %>%
count() %>%
ungroup() %>%
ggplot(mapping = aes(reorder_within(trans, n, class), n)) +
geom_bar(stat = "identity", scale = "free") +
facet_wrap(~ class)
mpg %>%
group_by(class, trans) %>%
count() %>%
ungroup() %>%
ggplot(mapping = aes(reorder_within(trans, n, class), n)) +
geom_bar(stat = "identity", scale = "free") +
facet_wrap(~ class)
mpg %>%
group_by(class, trans) %>%
count() %>%
ungroup() %>%
ggplot(mapping = aes(reorder_within(trans, n, class), n)) +
geom_bar(stat = "identity") +
facet_wrap(~ class, scale = "free")
mpg %>%
group_by(class, trans) %>%
count() %>%
ungroup() %>%
ggplot(mapping = aes(reorder_within(trans, n, class), n)) +
geom_bar(stat = "identity") +
facet_wrap(~ class, scale = "free")
mpg %>%
group_by(class, trans) %>%
count() %>%
ungroup() %>%
ggplot(mapping = aes(reorder(trans, n), n)) +
geom_bar(stat = "identity") +
facet_wrap(~ class, scale = "free")
mpg %>%
group_by(class, trans) %>%
count() %>%
ungroup() %>%
ggplot(mapping = aes(reorder_within(trans, n, class), n)) +
geom_bar(stat = "identity") +
facet_wrap(~ class, scale = "free")
mpg %>%
group_by(class, trans) %>%
count() %>%
ungroup() %>%
ggplot(mapping = aes(reorder(trans, n), n)) +
geom_bar(stat = "identity") +
facet_wrap(~ class, scale = "free")
mpg %>%
group_by(class, trans) %>%
count() %>%
ungroup() %>%
ggplot(mapping = aes(reorder_within(trans, n, class), n)) +
geom_bar(stat = "identity") +
facet_wrap(~ class, scale = "free")
glimpse(mpg)
mpg %>%
group_by(drv, trans) %>%
count() %>%
ungroup() %>%
ggplot(mapping = aes(reorder(trans, n), n)) +
geom_bar(stat = "identity") +
facet_wrap(~ drv, scale = "free")
mpg %>%
group_by(drv, trans) %>%
count() %>%
ungroup() %>%
ggplot(mapping = aes(reorder_within(trans, n, drv), n)) +
geom_bar(stat = "identity") +
facet_wrap(~ drv, scale = "free")
library(blogdown)
blogdown::serve_site()
blogdown::build_site()
